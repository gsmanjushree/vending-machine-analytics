
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Vending Insights: Data Analysis Project\n",
    "\n",
    "## Overview\n",
    "This notebook analyzes vending machine sales data to uncover insights about product performance, machine efficiency, and customer behavior patterns. The goal is to understand what drives sales and identify optimization opportunities.\n",
    "\n",
    "**Dataset**: 3 months of vending machine sales data (500+ transactions)\n",
    "**Tools**: Pandas, NumPy, Matplotlib, Seaborn\n",
    "**Focus**: Revenue analysis, demand patterns, inventory optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration\n",
    "\n",
    "Let's start by loading our dataset and understanding its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/vending_sales.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Feature Engineering\n",
    "\n",
    "Now we'll clean the data and create useful derived features for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Create derived features\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['revenue'] = df['price'] * df['quantity']\n",
    "\n",
    "# Check for any data quality issues\n",
    "print(f\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nData validation - Stock consistency:\")\n",
    "stock_check = (df['stock_after'] == df['stock_before'] - df['quantity']).all()\n",
    "print(f\"Stock calculations consistent: {stock_check}\")\n",
    "\n",
    "print(f\"\\nDataset summary after cleaning:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Revenue Analysis\n",
    "\n",
    "Let's explore the revenue patterns and understand which products and machines are performing best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic revenue metrics\n",
    "total_revenue = df['revenue'].sum()\n",
    "avg_order_value = df['revenue'].mean()\n",
    "total_transactions = len(df)\n",
    "\n",
    "print(f\"=== REVENUE SUMMARY ===\")\n",
    "print(f\"Total Revenue: ${total_revenue:,.2f}\")\n",
    "print(f\"Average Order Value: ${avg_order_value:.2f}\")\n",
    "print(f\"Total Transactions: {total_transactions:,}\")\n",
    "\n",
    "# Revenue by product\n",
    "revenue_by_product = df.groupby('product')['revenue'].sum().sort_values(ascending=False)\n",
    "print(f\"\\n=== REVENUE BY PRODUCT ===\")\n",
    "for product, revenue in revenue_by_product.items():\n",
    "    percentage = (revenue / total_revenue) * 100\n",
    "    print(f\"{product}: ${revenue:.2f} ({percentage:.1f}%)\")\n",
    "\n",
    "# Revenue by machine\n",
    "revenue_by_machine = df.groupby('machine_id')['revenue'].sum().sort_values(ascending=False)\n",
    "print(f\"\\n=== REVENUE BY MACHINE ===\")\n",
    "for machine, revenue in revenue_by_machine.items():\n",
    "    percentage = (revenue / total_revenue) * 100\n",
    "    print(f\"{machine}: ${revenue:.2f} ({percentage:.1f}%)\")\n",
    "\n",
    "# Revenue by location type\n",
    "revenue_by_location = df.groupby('location_type')['revenue'].sum().sort_values(ascending=False)\n",
    "print(f\"\\n=== REVENUE BY LOCATION ===\")\n",
    "for location, revenue in revenue_by_location.items():\n",
    "    percentage = (revenue / total_revenue) * 100\n",
    "    print(f\"{location}: ${revenue:.2f} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Demand Pattern Analysis\n",
    "\n",
    "Understanding when and how demand varies helps with inventory planning and staffing decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily revenue analysis\n",
    "daily_revenue = df.groupby('date')['revenue'].sum().reset_index()\n",
    "daily_revenue['date'] = pd.to_datetime(daily_revenue['date'])\n",
    "\n",
    "# 7-day rolling averages per machine\n",
    "machine_daily = df.groupby(['machine_id', 'date'])['quantity'].sum().reset_index()\n",
    "machine_daily['date'] = pd.to_datetime(machine_daily['date'])\n",
    "\n",
    "rolling_averages = {}\n",
    "for machine in df['machine_id'].unique():\n",
    "    machine_data = machine_daily[machine_daily['machine_id'] == machine].set_index('date')\n",
    "    machine_data = machine_data.reindex(pd.date_range(machine_data.index.min(), machine_data.index.max(), freq='D'), fill_value=0)\n",
    "    rolling_avg = machine_data['quantity'].rolling(window=7, min_periods=1).mean()\n",
    "    rolling_averages[machine] = rolling_avg\n",
    "\n",
    "print(f\"=== DEMAND PATTERNS ===\")\n",
    "\n",
    "# Hour of day analysis\n",
    "hourly_sales = df.groupby('hour')['quantity'].sum()\n",
    "peak_hour = hourly_sales.idxmax()\n",
    "print(f\"Peak sales hour: {peak_hour}:00 ({hourly_sales[peak_hour]} items sold)\")\n",
    "\n",
    "# Day of week analysis\n",
    "daily_sales = df.groupby('day_of_week')['quantity'].sum()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_sales = daily_sales.reindex(day_order)\n",
    "peak_day = daily_sales.idxmax()\n",
    "print(f\"Peak sales day: {peak_day} ({daily_sales[peak_day]} items sold)\")\n",
    "\n",
    "# Weather impact\n",
    "weather_sales = df.groupby('rain').agg({'quantity': 'sum', 'temperature_c': 'mean'})\n",
    "print(f\"\\n=== WEATHER IMPACT ===\")\n",
    "print(f\"Rainy days - Total sales: {weather_sales.loc[1, 'quantity']}, Avg temp: {weather_sales.loc[1, 'temperature_c']:.1f}°C\")\n",
    "print(f\"Dry days - Total sales: {weather_sales.loc[0, 'quantity']}, Avg temp: {weather_sales.loc[0, 'temperature_c']:.1f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inventory Optimization Analysis\n",
    "\n",
    "Let's analyze stock levels and calculate optimal reorder points and safety stock levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate demand statistics for each machine-product combination\n",
    "demand_stats = df.groupby(['machine_id', 'product'])['quantity'].agg(['mean', 'std', 'count']).reset_index()\n",
    "demand_stats.columns = ['machine_id', 'product', 'avg_demand', 'demand_std', 'frequency']\n",
    "\n",
    "# Calculate reorder point and safety stock\n",
    "# Assuming 3-day lead time and 95% service level (Z = 1.65)\n",
    "LEAD_TIME_DAYS = 3\n",
    "SERVICE_LEVEL_Z = 1.65\n",
    "\n",
    "demand_stats['daily_demand'] = demand_stats['avg_demand'] * demand_stats['frequency'] / 90  # 90 days of data\n",
    "demand_stats['lead_time_demand'] = demand_stats['daily_demand'] * LEAD_TIME_DAYS\n",
    "demand_stats['safety_stock'] = SERVICE_LEVEL_Z * demand_stats['demand_std'] * np.sqrt(LEAD_TIME_DAYS)\n",
    "demand_stats['reorder_point'] = demand_stats['lead_time_demand'] + demand_stats['safety_stock']\n",
    "\n",
    "# Round values for practical implementation\n",
    "demand_stats['safety_stock'] = np.ceil(demand_stats['safety_stock'].fillna(0))\n",
    "demand_stats['reorder_point'] = np.ceil(demand_stats['reorder_point'].fillna(0))\n",
    "\n",
    "print(f\"=== INVENTORY OPTIMIZATION RECOMMENDATIONS ===\")\n",
    "print(f\"\nTop 10 Machine-Product combinations by daily demand:\")\n",
    "top_demand = demand_stats.nlargest(10, 'daily_demand')[['machine_id', 'product', 'daily_demand', 'reorder_point', 'safety_stock']]\n",
    "print(top_demand.to_string(index=False))\n",
    "\n",
    "# Detect potential stockouts\n",
    "current_stock = df.groupby(['machine_id', 'product'])['stock_after'].last().reset_index()\n",
    "stock_analysis = current_stock.merge(demand_stats[['machine_id', 'product', 'reorder_point']], on=['machine_id', 'product'])\n",
    "stockout_risk = stock_analysis[stock_analysis['stock_after'] <= stock_analysis['reorder_point']]\n",
    "\n",
    "print(f\"\\n=== STOCKOUT ALERTS ===\")\n",
    "if len(stockout_risk) > 0:\n",
    "    print(f\"⚠️  {len(stockout_risk)} machine-product combinations need restocking:\")\n",
    "    for _, row in stockout_risk.iterrows():\n",
    "        print(f\"{row['machine_id']} - {row['product']}: Current stock {row['stock_after']}, Reorder at {row['reorder_point']}\")\n",
    "else:\n",
    "    print(f\"✅ All machines have adequate stock levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Price Sensitivity Analysis\n",
    "\n",
    "Let's simulate the impact of a price change on revenue to understand price elasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 10% price increase for Soda\n",
    "PRODUCT_TO_TEST = 'Soda'\n",
    "PRICE_INCREASE = 0.10\n",
    "\n",
    "# Current performance\n",
    "current_soda_sales = df[df['product'] == PRODUCT_TO_TEST]\n",
    "current_units = current_soda_sales['quantity'].sum()\n",
    "current_revenue = current_soda_sales['revenue'].sum()\n",
    "current_price = current_soda_sales['price'].iloc[0]\n",
    "\n",
    "# Simulate demand elasticity (assume -0.5 elasticity: 10% price increase = 5% demand decrease)\n",
    "DEMAND_ELASTICITY = -0.5\n",
    "demand_change = DEMAND_ELASTICITY * PRICE_INCREASE\n",
    "new_demand_multiplier = 1 + demand_change\n",
    "\n",
    "# Calculate new scenario\n",
    "new_price = current_price * (1 + PRICE_INCREASE)\n",
    "new_units = current_units * new_demand_multiplier\n",
    "new_revenue = new_units * new_price\n",
    "\n",
    "revenue_impact = new_revenue - current_revenue\n",
    "revenue_change_pct = (revenue_impact / current_revenue) * 100\n",
    "\n",
    "print(f\"=== PRICE SENSITIVITY ANALYSIS: {PRODUCT_TO_TEST} ===\")\n",
    "print(f\"\nCurrent Scenario:\")\n",
    "print(f\"  Price: ${current_price:.2f}\")\n",
    "print(f\"  Units sold: {current_units}\")\n",
    "print(f\"  Revenue: ${current_revenue:.2f}\")\n",
    "\n",
    "print(f\"\nWith {PRICE_INCREASE*100}% price increase:\")\n",
    "print(f\"  New price: ${new_price:.2f}\")\n",
    "print(f\"  Estimated units: {new_units:.0f} ({demand_change*100:+.1f}%)\")\n",
    "print(f\"  Estimated revenue: ${new_revenue:.2f}\")\n",
    "print(f\"  Revenue impact: ${revenue_impact:+.2f} ({revenue_change_pct:+.1f}%)\")\n",
    "\n",
    "if revenue_impact > 0:\n",
    "    print(f\"💡 Recommendation: Price increase would be profitable!\")\n",
    "else:\n",
    "    print(f\"⚠️  Recommendation: Price increase would reduce overall revenue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Visualizations\n",
    "\n",
    "Let's create visualizations to better understand our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Top Products by Revenue (Bar Chart)\n",
    "plt.subplot(2, 3, 1)\n",
    "revenue_by_product.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Revenue by Product', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('Revenue ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(revenue_by_product):\n",
    "    plt.text(i, v + 1, f'${v:.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Daily Revenue per Machine (Line Chart)\n",
    "plt.subplot(2, 3, 2)\n",
    "daily_machine_revenue = df.groupby(['date', 'machine_id'])['revenue'].sum().reset_index()\n",
    "daily_machine_revenue['date'] = pd.to_datetime(daily_machine_revenue['date'])\n",
    "\n",
    "for machine in df['machine_id'].unique():\n",
    "    machine_data = daily_machine_revenue[daily_machine_revenue['machine_id'] == machine]\n",
    "    plt.plot(machine_data['date'], machine_data['revenue'], marker='o', linewidth=2, label=machine)\n",
    "\n",
    "plt.title('Daily Revenue by Machine', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Daily Revenue ($)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# 3. Sales Heatmap: Hour vs Product\n",
    "plt.subplot(2, 3, 3)\n",
    "heatmap_data = df.pivot_table(values='quantity', index='hour', columns='product', aggfunc='sum', fill_value=0)\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='YlOrRd', cbar_kws={'label': 'Units Sold'})\n",
    "plt.title('Sales Heatmap: Hour vs Product', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Product')\n",
    "plt.ylabel('Hour of Day')\n",
    "\n",
    "# 4. Revenue by Location Type\n",
    "plt.subplot(2, 3, 4)\n",
    "revenue_by_location.plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Revenue Distribution by Location', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('')\n",
    "\n",
    "# 5. Hourly Sales Pattern\n",
    "plt.subplot(2, 3, 5)\n",
    "hourly_sales.plot(kind='bar', color='lightgreen', edgecolor='black')\n",
    "plt.title('Sales by Hour of Day', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Units Sold')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 6. Temperature vs Sales\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.scatter(df['temperature_c'], df['quantity'], alpha=0.6, color='coral')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['temperature_c'], df['quantity'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['temperature_c'].sort_values(), p(df['temperature_c'].sort_values()), \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.title('Temperature vs Sales Volume', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature (°C)')\n",
    "plt.ylabel('Quantity Sold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vending_analysis_charts.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Visualizations saved as 'vending_analysis_charts.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Recommendations\n",
    "\n",
    "Based on our analysis, here are the main findings and actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary insights\n",
    "print(\"=== 🔍 KEY INSIGHTS ===\\n\")\n",
    "\n",
    "print(\"1. 📈 REVENUE PERFORMANCE\")\n",
    "top_product = revenue_by_product.index[0]\n",
    "top_product_pct = (revenue_by_product.iloc[0] / total_revenue) * 100\n",
    "print(f\"   • {top_product} is the top revenue generator ({top_product_pct:.1f}% of total sales)\")\n",
    "\n",
    "top_machine = revenue_by_machine.index[0]\n",
    "top_machine_pct = (revenue_by_machine.iloc[0] / total_revenue) * 100\n",
    "print(f\"   • Machine {top_machine} generates the most revenue ({top_machine_pct:.1f}% of total)\")\n",
    "\n",
    "print(f\"\\n2. ⏰ DEMAND PATTERNS\")\n",
    "print(f\"   • Peak sales occur at {peak_hour}:00 ({hourly_sales[peak_hour]} units)\")\n",
    "print(f\"   • {peak_day} is the busiest day ({daily_sales[peak_day]} units sold)\")\n",
    "\n",
    "# Temperature correlation\n",
    "temp_corr = df['temperature_c'].corr(df['quantity'])\n",
    "print(f\"   • Temperature correlation with sales: {temp_corr:.3f}\")\n",
    "\n",
    "print(f\"\\n3. 📦 INVENTORY INSIGHTS\")\n",
    "stockout_count = len(stockout_risk)\n",
    "if stockout_count > 0:\n",
    "    print(f\"   • {stockout_count} machine-product combinations need immediate restocking\")\n",
    "else:\n",
    "    print(f\"   • All machines currently have adequate stock levels\")\n",
    "\n",
    "avg_safety_stock = demand_stats['safety_stock'].mean()\n",
    "print(f\"   • Average recommended safety stock: {avg_safety_stock:.1f} units\")\n",
    "\n",
    "print(f\"\\n4. 💰 PRICING OPPORTUNITIES\")\n",
    "if revenue_impact > 0:\n",
    "    print(f\"   • {PRODUCT_TO_TEST} price increase could generate additional ${revenue_impact:.2f} revenue\")\n",
    "else:\n",
    "    print(f\"   • {PRODUCT_TO_TEST} appears price-sensitive; focus on volume over margin\")\n",
    "\n",
    "print(f\"\\n=== 🎯 ACTIONABLE RECOMMENDATIONS ===\\n\")\n",
    "\n",
    "print(f\"1. 🔄 OPERATIONAL OPTIMIZATION\")\n",
    "print(f\"   • Schedule restocking during off-peak hours (avoid {peak_hour}:00)\")\n",
    "print(f\"   • Increase {top_product} inventory across all machines\")\n",
    "print(f\"   • Focus promotional efforts on {peak_day}s\")\n",
    "\n",
    "print(f\"\\n2. 📊 INVENTORY MANAGEMENT\")\n",
    "print(f\"   • Implement automated reorder alerts based on calculated reorder points\")\n",
    "print(f\"   • Maintain safety stock levels to prevent stockouts\")\n",
    "print(f\"   • Monitor {top_machine} more closely due to high sales volume\")\n",
    "\n",
    "print(f\"\\n3. 💡 GROWTH OPPORTUNITIES\")\n",
    "if temp_corr > 0.1:\n",
    "    print(f\"   • Consider weather-based inventory adjustments (higher temp = more sales)\")\n",
    "elif temp_corr < -0.1:\n",
    "    print(f\"   • Stock more hot beverages during cooler weather\")\n",
    "else:\n",
    "    print(f\"   • Weather has minimal impact on sales patterns\")\n",
    "\n",
    "print(f\"   • Test premium pricing for high-demand products during peak hours\")\n",
    "print(f\"   • Consider expanding successful machine locations to similar venues\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
